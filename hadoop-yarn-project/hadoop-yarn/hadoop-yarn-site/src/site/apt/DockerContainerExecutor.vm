
~~ Licensed under the Apache License, Version 2.0 (the "License");
~~ you may not use this file except in compliance with the License.
~~ You may obtain a copy of the License at
~~
~~   http://www.apache.org/licenses/LICENSE-2.0
~~
~~ Unless required by applicable law or agreed to in writing, software
~~ distributed under the License is distributed on an "AS IS" BASIS,
~~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
~~ See the License for the specific language governing permissions and
~~ limitations under the License. See accompanying LICENSE file.

  ---
  Hadoop Map Reduce Next Generation-${project.version} - Docker Container Executor
  ---
  ---
  ${maven.build.timestamp}

Docker Container Executor

%{toc|section=1|fromDepth=0}

* {Overview}

  Docker (https://www.docker.io/) combines an easy-to-use interface to
Linux containers with easy-to-construct image files for those
containers.  In short, Docker launches very light weight "virtual
machines.

  The Docker Conatiner Executor (DCE) allows the YARN NodeManager to
launch YARN containers into Docker containers.  Users can specify the
Docker Images they want for their YARN containers.  These containers
provide a custom software environment in which the user's code runs,
isolated from the software environment of the NodeManager.  These
containers can include special libraries needed by the application,
and they can have different versions of Perl, Python, and even Java
than what is installed on the NodeManager.  Indeed, these containers
can run a different flavor of Linux than what is running on the
NodeManager -- although the YARN container will share the kernel of
the NodeManager, and (for MapReduce and Tez) JAVA_HOME of the YARN
container must match that of the NodeManager.

   Docker for YARN provides both consistency (all YARN containers will
have the same software environment) and isolation (no interference
with whatever is installed on the physical machine).
  
* {Cluster Configuration}

   Docker Container Executor runs in non-secure mode of HDFS and
YARN. It will not run in secure mode, and will exit if it detects
secure mode.

   The DockerContainerExecutor requires Docker daemon to be running on
the NodeManager, and the Docker client installed and able start Docker
containers.  To prevent timeouts while starting jobs, the Docker
images to be used by a job should already be downloaded in the
NodeManagers. [[HOW DO YOU DO THIS??]]

   The following properties must [[*MUST* OR *CAN*?  ARE THERE DEFAULTS]] be set in yarn-site.xml:
----
<property>
  <name>yarn.nodemanager.docker-image.name</name>
  <value>dockerfile/java</value>
  <description>
     This image is used by all nodemanagers to launch containers.
  </description>
</property>
----
<property>
  <name>yarn.nodemanager.docker-run.args</name>
  <value>--rm --net=host</value>
  <description>
     This arguments to pass to the 'docker run' invocation.
  </description>
</property>
----
<property>
 <name>yarn.nodemanager.docker-executor.name</name>
  <value>docker</value>
  <description>
     Name or path to the Docker client.
  </description>
</property>
----
<property>
  <name>yarn.nodemanager.docker-run.pre-command</name>
  <value></value>
  <description>
     Optional commands to run before invoking the container script.
  </description>
</property>
----
<property>
  <name>yarn.nodemanager.container-executor.class</name>
  <value>org.apache.hadoop.yarn.server.nodemanager.DockerContainerExecutor</value>
  <description>
     This is the container executor setting that ensures that all jobs are started with the DockerContainerExecutor.
  </description>
</property>
----


   Administrators are expected to include both --rm and --net=host in
yarn.nodemanager.docker-run.args.  --rm ensures that all containers
that are killed are cleaned up. --net=host makes the container share
the host's network, which allows all Hadoop proceses (including the
Application Master) to talk to the containers as if they where just
processes on the same host as the container's NodeManager.

   Administrators should be aware that DCE doesn't currently provide
name-space isolation.  This means, in particular, that software
running as root in the YARN container will have root priveleges in the
underlying NodeManager.  Put differently, DCE currently provides no
better security guarantees than YARN's Linux Container Executor.

* {Tips for connecting to a secure docker repository}

To connect to a secure docker repository, you can use the folling invocation:
----
docker login [OPTIONS] [SERVER]

Register or log in to a Docker registry server, if no server is specified "https://index.docker.io/v1/" is the default.

  -e, --email=""       Email
  -p, --password=""    Password
  -u, --username=""    Username
----
If you want to login to a self-hosted registry you can specify this by adding the server name.
----
docker login localhost:8080
----

* {Job Configuration}

Currently you cannot configure any of the Docker settings with the job configuration.


* {Docker Image requirements}

   The Docker Images used for YARN containers must meet the following
requirements:

   * As is usual for Docker, the Docker containers my run a different
version or flavor of Linux than the underlying NodeManager, but the OS
of the container must be compatible with the kernal of the
NodeManager.  [[I DON'T REALLY KNOW WHAT I'M TALKING ABOUT -- CHECK
WITH DINESH.]]

   * The MapReduce and Tez app frameworks launch a Java process inside
their YARN containers.  As a result, the Docker image for those
containers must have Java installed -- and further, the location of
JAVA_HOME in this container needs to match the underlying NodeManager.
Further, the Docker image for those containers must also have Hadoop
installed in the same location as the NodeManager.

[[OTHER REQUIREMENTS]]


* {Working example of yarn launched docker containers.}

